# 参数调优完整指南

> 碳价格预测系统参数优化全流程文档  
> **版本**: v5.0 | **更新日期**: 2025-10-17

---

## 📚 目录

1. [调优概述](#调优概述)
2. [Baseline基线报告](#baseline基线报告)
3. [第四轮优化策略](#第四轮优化策略)
4. [第五轮优化策略](#第五轮优化策略)
5. [执行指南](#执行指南)
6. [问题诊断与修复](#问题诊断与修复)
7. [调优结果分析](#调优结果分析)

---

## 📊 调优概述

### 调优目标

参数调优的主要目标是找到最佳的模型配置，以提高预测精度和稳定性：

- **LSTM模型**: R² > 0.89, RMSE < 35
- **Transformer模型**: R² > 0.77, RMSE < 50
- **RandomForest模型**: 维持 R² > 0.93

### 调优历史

| 轮次 | 时间 | LSTM R² | Transformer R² | 主要策略 |
|------|------|---------|----------------|---------|
| **Baseline** | 2025-10-14 | -0.2348 | -2.0934 | 初始配置 |
| **第二轮** | 2025-10-14 | 0.8768 | -0.93 | batch_size优化 |
| **第三轮** | 2025-10-14 | 0.7227 | -1.2344 | 性能退化 |
| **第四轮** | 2025-10-14 | 0.8904 | 0.7874 | 激进简化 |
| **第五轮** | 2025-10-15 | **目标>0.89** | **目标>0.77** | 精细调优 |

---

## 🎯 Baseline基线报告

### 数据概览

| 指标 | 数值 |
|------|------|
| 数据点数量 | 1,247 |
| 特征数量 | 45 |
| 时间范围 | 2016-09-22 至 2023-12-29 |
| 目标变量 | coal_price |
| 价格范围 | 463.00 - 1,628.00 |

### Baseline模型性能

| 排名 | 模型 | R² | RMSE | MAE | MAPE | 方向准确率 |
|------|------|-----|------|-----|------|-----------|
| 🥇 1 | **RandomForest** | **0.9430** | **40.69** | **29.58** | **2.81%** | **58.63%** |
| 🥈 2 | GradientBoosting | 0.8756 | 60.13 | 42.06 | 3.94% | 58.63% |
| 🥉 3 | XGBoost | 0.6603 | 99.38 | 58.99 | 4.99% | 51.81% |
| 4 | LSTM | -0.2348 | 115.15 | 103.12 | 11.00% | 36.51% |
| 5 | Transformer | -2.0934 | 182.25 | 160.64 | 17.29% | 31.22% |

### Baseline配置

```python
BASELINE_CONFIG = {
    'lstm_config': {
        'units': [64, 32],
        'dropout': 0.2,
        'epochs': 100,
        'batch_size': 16
    },
    'transformer_config': {
        'd_model': 256,
        'num_heads': 8,
        'num_layers': 4,
        'dff': 512,
        'dropout': 0.1,
        'epochs': 50
    }
}
```

### 关键发现

1. **RandomForest表现优异**: R² 达到 0.943，接近完美预测
2. **深度学习模型欠拟合**: LSTM 和 Transformer 的 R² 为负值
3. **特征工程有效**: 对数变换、移动平均等技术指标提供了强预测信号

---

## 🔧 第四轮优化策略

### 问题分析

#### 最新运行结果 (2025-10-14 22:45)

| 模型 | R² | RMSE | 状态 | 变化趋势 |
|------|-----|------|------|---------|
| RandomForest | 0.9290 | 45.44 | ✅ 优秀 | ↓ (从0.9430) |
| GradientBoosting | 0.8742 | 60.47 | ✅ 优秀 | ≈ 稳定 |
| LSTM | 0.7227 | 54.57 | ⚠️ 良好 | ↓↓ (从0.8768) |
| XGBoost | 0.6603 | 99.38 | ⚠️ 良好 | ≈ 稳定 |
| Transformer | -1.2344 | 154.90 | ❌ 过拟合 | ≈ 仍差 |

#### 核心问题

1. **LSTM性能大幅退化**: 从R²=0.8768降至0.7227（下降17.6%）
2. **Transformer持续失败**: 所有尝试的R²均为负值
3. **可能的原因**: 随机性影响、训练不充分、局部最优

### 优化策略

#### LSTM优化（10个配置）

**组1: 基线强化（配置1-3）**

```python
# 配置1: 延长训练轮数
{'units': [64, 32], 'dropout': 0.2, 'epochs': 150, 'batch_size': 8}

# 配置2-3: 降低dropout，增强拟合
{'units': [64, 32], 'dropout': 0.15, 'epochs': 150, 'batch_size': 8}
{'units': [64, 32], 'dropout': 0.10, 'epochs': 150, 'batch_size': 8}
```

**组2: 网络容量优化（配置4-5）**

```python
# 配置4: 增加宽度
{'units': [96, 48], 'dropout': 0.2, 'epochs': 120, 'batch_size': 8}

# 配置5: 增加深度
{'units': [96, 64, 32], 'dropout': 0.2, 'epochs': 120, 'batch_size': 8}
```

**组3: 组合优化（配置6-8）**

```python
# 配置6: 宽网络+低dropout
{'units': [96, 48], 'dropout': 0.15, 'epochs': 150, 'batch_size': 8}

# 配置7: 极小batch size
{'units': [64, 32], 'dropout': 0.2, 'epochs': 150, 'batch_size': 4}

# 配置8: 大网络+高正则
{'units': [128, 64], 'dropout': 0.25, 'epochs': 120, 'batch_size': 8}
```

**组4: 精细调优（配置9-10）**

```python
# 配置9-10: 在最优区间微调
{'units': [80, 40], 'dropout': 0.18, 'epochs': 140, 'batch_size': 8}
{'units': [72, 36], 'dropout': 0.16, 'epochs': 140, 'batch_size': 8}
```

#### Transformer优化（8个配置）

**策略核心**: 激进简化 + 极高正则化

**模型复杂度对比**

| 配置 | d_model | layers | 参数量 | 相对复杂度 |
|------|---------|--------|--------|----------|
| 原配置 | 256 | 4 | ~2.6M | 100% |
| 配置1 | 16 | 1 | ~5K | 0.2% |
| 配置2 | 24 | 1 | ~11K | 0.4% |
| 配置3 | 32 | 1 | ~20K | 0.8% |

**组1: 极简单层（配置1-4）**

```python
# 配置1: 最激进简化
{'d_model': 16, 'num_heads': 2, 'num_layers': 1, 'dff': 64, 
 'dropout': 0.6, 'epochs': 100, 'batch_size': 8}

# 配置2: 超轻量级
{'d_model': 24, 'num_heads': 2, 'num_layers': 1, 'dff': 96,
 'dropout': 0.5, 'epochs': 120, 'batch_size': 8}

# 配置3: 小模型+长训练
{'d_model': 32, 'num_heads': 2, 'num_layers': 1, 'dff': 128,
 'dropout': 0.5, 'epochs': 150, 'batch_size': 8}
```

### 第四轮最佳结果

```python
# LSTM最佳配置（配置10）
LSTM_BEST_CONFIG = {
    'units': [72, 36],
    'dropout': 0.16,
    'epochs': 140,
    'batch_size': 8
}
# R²: 0.8904, RMSE: 34.27

# Transformer最佳配置（配置5）
TRANSFORMER_BEST_CONFIG = {
    'd_model': 16,
    'num_heads': 2,
    'num_layers': 2,
    'dff': 64,
    'dropout': 0.6,
    'epochs': 100,
    'batch_size': 8
}
# R²: 0.7874, RMSE: 47.76
```

---

## 🚀 第五轮优化策略

### 当前状态分析

**基于2025-10-15 00:53报告**

| 模型 | R² | RMSE | MAE | MAPE | 状态 |
|------|-----|------|-----|------|------|
| RandomForest | 0.9290 | 45.44 | 33.52 | 3.18% | ✅ 优秀 |
| GradientBoosting | 0.8742 | 60.47 | 43.30 | 4.04% | ✅ 优秀 |
| Transformer | 0.7746 | 49.19 | 42.61 | 4.47% | ✅ 良好 |
| XGBoost | 0.6603 | 99.38 | 58.99 | 4.99% | ⚠️ 良好 |
| LSTM | 0.5740 | 67.63 | 54.61 | 5.67% | ❌ 待改进 |

### 关键问题

1. **LSTM严重退化**: 从第四轮的R²=0.8904降至0.574（下降35.5%）
2. **可能原因**: 主配置文件被覆盖，未使用第四轮最佳配置
3. **Transformer保持稳定**: 从0.7874微降至0.7746，简化策略有效

### 优化目标

- **LSTM恢复**: R² > 0.89（重现第四轮最佳水平）
- **Transformer稳定**: R² ≥ 0.77 或突破至 R² > 0.80
- **终极目标**: LSTM R² > 0.92, Transformer R² > 0.85

### 12组实验配置

#### 第一组：基线恢复（3组）

```python
# 配置1: 第四轮最佳配置基线
LSTM: units=[72,36], dropout=0.16, epochs=140, batch_size=8
Transformer: d_model=16, num_heads=2, num_layers=2, dff=64, dropout=0.6, epochs=100

# 配置2: LSTM延长训练+10%
LSTM: epochs=154  # +10%

# 配置3: LSTM降低dropout-10%
LSTM: dropout=0.14  # -10%
```

#### 第二组：容量调整（3组）

```python
# 配置4: LSTM增加神经元+10%
LSTM: units=[80,40]

# 配置5: Transformer扩容d_model+25%
Transformer: d_model=20, dff=80

# 配置6: Transformer降低dropout
Transformer: dropout=0.55
```

#### 第三组：联合优化（3组）

```python
# 配置7: 联合增加训练轮数
LSTM: epochs=160
Transformer: epochs=120

# 配置8: 联合极小batch_size=4
LSTM: batch_size=4
Transformer: batch_size=4

# 配置9: LSTM增加深度三层
LSTM: units=[72,48,24]
```

#### 第四组：极致优化（3组）

```python
# 配置10: Transformer增加深度三层
Transformer: num_layers=3, dropout=0.65

# 配置11: LSTM极致优化-多维增强
LSTM: units=[80,40], dropout=0.14, epochs=160

# 配置12: Transformer极致优化-突破R²0.80
Transformer: d_model=24, dff=96, dropout=0.55, epochs=120
```

### 参数调整策略

#### LSTM优化维度

| 维度 | 第四轮最佳 | 调整范围 | 策略 |
|------|-----------|---------|------|
| units | [72, 36] | [64-80, 32-40] | ±10%微调 + 三层探索 |
| dropout | 0.16 | 0.14-0.18 | 小步长调整 |
| epochs | 140 | 140-160 | 延长训练 |
| batch_size | 8 | 4-8 | 极小batch测试 |

#### Transformer优化维度

| 维度 | 第四轮最佳 | 调整范围 | 策略 |
|------|-----------|---------|------|
| d_model | 16 | 16-24 | 容量扩展 |
| num_heads | 2 | 2 | 保持稳定 |
| num_layers | 2 | 2-3 | 深度探索 |
| dropout | 0.6 | 0.55-0.65 | 平衡过拟合 |
| epochs | 100 | 100-120 | 延长训练 |

### 预期成果

#### 最佳情况（概率30%）
- LSTM: R² ≥ 0.92, RMSE < 32
- Transformer: R² ≥ 0.85, RMSE < 45

#### 理想情况（概率50%）
- LSTM: R² ≥ 0.89, RMSE < 35
- Transformer: R² ≥ 0.77, RMSE < 50

#### 保守情况（概率20%）
- LSTM: R² ≥ 0.85, RMSE < 40
- Transformer: R² ≥ 0.75, RMSE < 52

---

## 📋 执行指南

### 快速开始

#### 方法1：使用自动脚本（推荐）✅

```bash
cd /Users/Jason/Desktop/code/AI/parameter
./run_tuning.sh
```

**优点**：
- ✅ 自动防止Mac休眠
- ✅ 显示开始/结束时间
- ✅ 一键启动

#### 方法2：手动使用caffeinate

```bash
cd /Users/Jason/Desktop/code/AI/parameter
caffeinate -i python3 parameter_tuning.py
```

**参数说明**：
- `-i`：防止系统在空闲时休眠
- `-d`：防止显示器休眠（可选）
- `-s`：防止系统在接AC电源时休眠（可选）

### 运行时间预估

| 阶段 | 配置数 | 预计耗时 |
|------|--------|---------|
| 配置1-3 (基线恢复) | 3 | 36分钟 |
| 配置4-6 (容量调整) | 3 | 36分钟 |
| 配置7-9 (联合优化) | 3 | 45分钟 |
| 配置10-12 (极致优化) | 3 | 45分钟 |
| **总计** | **12** | **~162分钟 (2.7小时)** |

**建议缓冲时间**: +20分钟  
**预留总时长**: **3小时**

### 实时监控

#### 监控脚本进度

```bash
# 方法1：查看输出日志
tail -f /Users/Jason/Desktop/code/AI/parameter/parameter_tuning.txt

# 方法2：使用watch命令
watch -n 30 'tail -20 /Users/Jason/Desktop/code/AI/parameter/parameter_tuning.txt'
```

#### 检查进度

```bash
# 查看已完成的配置数
grep -c "调优时间:" parameter_tuning.txt
```

### 防中断检查清单

运行前确认：
- [ ] 笔记本已连接电源
- [ ] 电池电量 > 50%
- [ ] 网络稳定
- [ ] 硬盘空间 > 5GB
- [ ] 已使用caffeinate或关闭自动休眠
- [ ] 终端窗口不会意外关闭

---

## 🔍 问题诊断与修复

### 核心问题：目标列名不匹配

#### 问题分析

| 程序 | 目标列名 | 影响 |
|------|---------|------|
| **参数优化程序** | `'coal_price'` | 预测煤炭价格 |
| **主程序（修改前）** | `'carbon_price'` | 预测碳价格 |
| **主程序（修改后）** | `'coal_price'` | ✅ 已统一 |

#### 影响分析

- ❌ 不同的目标变量 = 完全不同的预测任务
- ❌ 不同的数据分布 = 特征工程结果不同
- ❌ 不同的标准化范围 = 模型学习模式不同

#### 解决方案

**修改位置**: `carbon_price_prediction.py` 第43行

```python
# 修改前
'target_column': 'carbon_price',

# 修改后
'target_column': 'coal_price',  # 修正：与parameter_tuning.py保持一致
```

### 数据文件问题

#### 问题：data.dta文件不存在

```python
# ❌ 错误的代码
system.load_data('data.dta')  # 该文件不存在！
```

#### 解决方案

```python
# ✅ 修复后
try:
    system.load_data('data.dta')
except FileNotFoundError:
    print("⚠️ data.dta未找到，创建示例数据...")
    system.create_sample_data()
```

### 配置一致性检查

#### 已确认一致的配置

| 配置项 | 参数优化程序 | 主程序 | 状态 |
|--------|------------|--------|------|
| LSTM units | [72, 36] | [72, 36] | ✅ 一致 |
| LSTM dropout | 0.16 | 0.16 | ✅ 一致 |
| LSTM epochs | 140 | 140 | ✅ 一致 |
| LSTM batch_size | 8 | 8 | ✅ 一致 |
| Transformer d_model | 16 | 16 | ✅ 一致 |
| Transformer num_heads | 2 | 2 | ✅ 一致 |
| Transformer num_layers | 2 | 2 | ✅ 一致 |
| Transformer dropout | 0.6 | 0.6 | ✅ 一致 |

---

## 📊 调优结果分析

### 验证建议

#### 立即验证

运行主程序并对比结果：

```bash
cd /Users/Jason/Desktop/code/AI
python3 carbon_price_prediction.py
```

**预期结果**（基于参数优化记录）：
- LSTM: R² ≈ 0.8669 ± 0.05
- Transformer: R² ≈ 0.5138 ± 0.05
- RandomForest: R² ≈ 0.9290（不受影响）

#### 多次运行验证稳定性

```bash
# 运行3次取平均值
for i in {1..3}; do
    echo "运行第 $i 次"
    python3 carbon_price_prediction.py
done
```

**判断标准**：
- ✅ **成功**：LSTM R² > 0.82，Transformer R² > 0.45
- ⚠️ **部分成功**：LSTM R² > 0.75，Transformer R² > 0.30
- ❌ **失败**：LSTM R² < 0.70，仍需进一步诊断

### 经验总结

#### 成功经验

1. ✅ **batch_size=8** 是LSTM的黄金配置
2. ✅ **极简Transformer**（d_model=16, 2层）有效防止过拟合
3. ✅ **dropout=0.6** 对Transformer至关重要
4. ✅ **units=[72,36]** 是LSTM的最佳容量

#### 改进重点

1. 🎯 严格复现第四轮最佳配置
2. 🎯 微调而非大幅跳跃
3. 🎯 联合优化双模型
4. 🎯 探索深度网络可能性

### 最佳实践

1. **配置管理**: 创建独立的配置文件，避免不一致
2. **数据管理**: 使用软链接或统一数据路径
3. **日志记录**: 增强日志，记录完整配置信息
4. **版本控制**: 使用Git管理代码和配置变更

---

## ⚠️ 风险提示

1. **过拟合风险**: 极端配置可能导致训练集表现好但泛化差
2. **训练时间**: 深层网络或大batch可能超时
3. **配置冲突**: 某些参数组合可能不兼容
4. **随机性**: TensorFlow随机种子影响，建议多次运行

---

## 📞 获取帮助

如果遇到问题，请检查：

1. **数据文件是否存在**: `ls -lh data.dta`
2. **目标列名是否匹配**: 打开数据文件确认列名
3. **Python环境**: `python3 --version`
4. **磁盘空间**: `df -h`

---

**文档版本**: v5.0  
**最后更新**: 2025-10-17  
**维护团队**: AI Research Team

