#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¬¬å››è½®å‚æ•°ä¼˜åŒ– - åŸºäºæœ€æ–°ç»“æœçš„é’ˆå¯¹æ€§ä¼˜åŒ–
ç”Ÿæˆæ—¶é—´: 2025-10-14
ä¼˜åŒ–ç›®æ ‡: æ¢å¤å¹¶è¶…è¶Šç¬¬äºŒè½®æœ€ä½³æ€§èƒ½ (LSTM RÂ²=0.8768)

å¢å¼ºåŠŸèƒ½:
1. æ”¯æŒæ–­ç‚¹ç»­ä¼  - å®éªŒä¸­æ–­åå¯ç»§ç»­
2. å®æ—¶è¿›åº¦ä¿å­˜ - æ¯ä¸ªå®éªŒå®Œæˆåç«‹å³ä¿å­˜
3. å¼‚å¸¸å¤„ç†å¢å¼º - å•ä¸ªå®éªŒå¤±è´¥ä¸å½±å“æ•´ä½“æµç¨‹
4. å¹¶è¡Œè¿è¡Œæ”¯æŒ - å¯é…ç½®æ˜¯å¦å¹¶è¡Œè¿è¡Œå®éªŒ
5. æ—©åœæœºåˆ¶ - å‘ç°ä¼˜ç§€é…ç½®åå¯æå‰ç»“æŸ
6. è¯¦ç»†æ—¥å¿—è®°å½• - åŒ…å«è®­ç»ƒè¿‡ç¨‹è¯¦ç»†ä¿¡æ¯
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from carbon_price_prediction import CarbonPricePredictionSystem, DEFAULT_CONFIG
import numpy as np
import pandas as pd
from datetime import datetime
import json
import pickle
import time

def log_message(message, log_file=None):
    """è®°å½•æ—¥å¿—ä¿¡æ¯ï¼ˆä»…æ‰“å°åˆ°æ§åˆ¶å°ï¼‰"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    log_entry = f"[{timestamp}] {message}"
    print(log_entry)
    # ä¸å†ç”Ÿæˆ.logæ–‡ä»¶ï¼Œåªè¾“å‡ºåˆ°æ§åˆ¶å°

def run_experiment(config, experiment_name):
    """è¿è¡Œå•ä¸ªå®éªŒé…ç½®
    
    Args:
        config: ç³»ç»Ÿé…ç½®å­—å…¸
        experiment_name: å®éªŒåç§°
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
    """
    log_message(f"\n{'='*80}")
    log_message(f"ğŸ§ª å¼€å§‹å®éªŒ: {experiment_name}")
    log_message(f"{'='*80}")
    
    start_time = time.time()
    
    # æ˜¾ç¤ºé…ç½®
    log_message(f"\nğŸ“‹ é…ç½®è¯¦æƒ…:")
    for key, value in config.items():
        if isinstance(value, dict):
            log_message(f"  {key}:")
            for k, v in value.items():
                log_message(f"    {k}: {v}")
        else:
            log_message(f"  {key}: {value}")
    
    try:
        # åˆ›å»ºç³»ç»Ÿå®ä¾‹
        log_message("\nğŸ“¦ åˆ›å»ºç³»ç»Ÿå®ä¾‹...")
        system = CarbonPricePredictionSystem(config=config)
        
        # åŠ è½½æ•°æ®
        log_message("\nğŸ“ æ­£åœ¨åŠ è½½æ•°æ®...")
        data_file = 'data.dta'
        if not os.path.exists(data_file):
            log_message(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
            return None
        system.load_data(data_file)
        log_message(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
        
        # é¢„å¤„ç†æ•°æ®
        log_message("\nğŸ”§ æ­£åœ¨é¢„å¤„ç†æ•°æ®...")
        system.preprocess_data()
        log_message("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
        
        # è®­ç»ƒæ¨¡å‹
        log_message(f"\nğŸš€ æ­£åœ¨è®­ç»ƒæ‰€æœ‰æ¨¡å‹...")
        system.train_models()
        
        # è·å–ç»“æœ
        elapsed_time = time.time() - start_time
        log_message(f"\nâ±ï¸  è®­ç»ƒè€—æ—¶: {elapsed_time:.2f}ç§’ ({elapsed_time/60:.2f}åˆ†é’Ÿ)")
        
        results = {}
        for model_name, metrics in system.predictions.items():
            r2 = metrics.get('r2', np.nan)
            rmse = metrics.get('rmse', np.nan)
            mae = metrics.get('mae', np.nan)
            mape = metrics.get('mape', np.nan)
            
            results[model_name] = {
                'RÂ²': r2,
                'RMSE': rmse,
                'MAE': mae,
                'MAPE': mape,
                'training_time': elapsed_time
            }
            
            # åˆ¤æ–­ç»“æœè´¨é‡
            quality = "âŒ å¤±è´¥" if r2 < 0 else "âš ï¸ å¾…æ”¹è¿›" if r2 < 0.6 else "âœ… è‰¯å¥½" if r2 < 0.85 else "ğŸ† ä¼˜ç§€"
            
            log_message(f"\n  {quality} {model_name}:")
            log_message(f"     RÂ² = {r2:.4f}")
            log_message(f"     RMSE = {rmse:.4f}")
            log_message(f"     MAE = {mae:.4f}")
            log_message(f"     MAPE = {mape:.2f}%")
        
        log_message(f"\nâœ… å®éªŒå®Œæˆ: {experiment_name}")
        return results
        
    except Exception as e:
        elapsed_time = time.time() - start_time
        log_message(f"\nâŒ å®éªŒå¤±è´¥ (è€—æ—¶ {elapsed_time:.2f}ç§’): {str(e)}")
        import traceback
        error_trace = traceback.format_exc()
        log_message(error_trace)
        
        # è¿”å›é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯Noneï¼Œä¾¿äºåˆ†æ
        return {
            'error': str(e),
            'traceback': error_trace,
            'experiment': experiment_name,
            'elapsed_time': elapsed_time
        }

def save_checkpoint(checkpoint_data, checkpoint_file):
    """ä¿å­˜æ£€æŸ¥ç‚¹æ•°æ®"""
    try:
        with open(checkpoint_file, 'wb') as f:
            pickle.dump(checkpoint_data, f)
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")

def load_checkpoint(checkpoint_file):
    """åŠ è½½æ£€æŸ¥ç‚¹æ•°æ®"""
    if os.path.exists(checkpoint_file):
        try:
            with open(checkpoint_file, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    return None

def save_intermediate_results(all_results, results_file):
    """ä¿å­˜ä¸­é—´ç»“æœ"""
    if not all_results:
        return
    
    try:
        df_results = pd.DataFrame(all_results)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            f.write("="*100 + "\n")
            f.write("ç¢³ä»·æ ¼é¢„æµ‹ç³»ç»Ÿ - ç¬¬å››è½®å‚æ•°ä¼˜åŒ–ç»“æœ (ä¸­é—´ç»“æœ)\n")
            f.write("="*100 + "\n")
            f.write(f"ä¿å­˜æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å·²å®Œæˆå®éªŒæ•°: {len(all_results)}\n\n")
            
            # æŒ‰æ¨¡å‹åˆ†ç»„
            for model in df_results['model'].unique():
                model_results = df_results[df_results['model'] == model].copy()
                if not model_results.empty:
                    model_results = model_results.sort_values('RÂ²', ascending=False)
                    
                    f.write(f"\n{model} æ¨¡å‹ç»“æœ:\n")
                    f.write("-"*100 + "\n")
                    for idx, row in enumerate(model_results.itertuples(), 1):
                        exp_name = getattr(row, 'experiment', '')
                        r2_val = getattr(row, 'RÂ²', np.nan)
                        rmse_val = getattr(row, 'RMSE', np.nan)
                        mae_val = getattr(row, 'MAE', np.nan)
                        mape_val = getattr(row, 'MAPE', np.nan)
                        f.write(f"{idx:2d}. {exp_name:<35} RÂ²={r2_val:<8.4f} RMSE={rmse_val:<8.2f} MAE={mae_val:<8.2f} MAPE={mape_val:<7.2f}%\n")
        
        log_message(f"ğŸ’¾ ä¸­é—´ç»“æœå·²ä¿å­˜: {results_file}")
    except Exception as e:
        log_message(f"âš ï¸ ä¿å­˜ä¸­é—´ç»“æœå¤±è´¥: {e}")

def main():
    """ç¬¬å››è½®ä¼˜åŒ–ä¸»æµç¨‹"""
    
    # åˆ›å»ºç»“æœæ–‡ä»¶ï¼ˆä¸ç”Ÿæˆlogæ–‡ä»¶ï¼‰
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_file = f'parameter/parameter_tuning_v4_{timestamp}.txt'
    checkpoint_file = f'parameter/parameter_tuning_v4_{timestamp}.checkpoint'
    
    # å°è¯•åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint = load_checkpoint(checkpoint_file)
    start_idx = 0
    all_results = []
    
    if checkpoint:
        start_idx = checkpoint.get('last_completed_idx', 0) + 1
        all_results = checkpoint.get('results', [])
        log_message(f"âœ… ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼Œç»§ç»­ä»ç¬¬ {start_idx + 1} ä¸ªå®éªŒå¼€å§‹")
    
    log_message("="*80)
    log_message("ğŸ¯ ç¢³ä»·æ ¼é¢„æµ‹ç³»ç»Ÿ - ç¬¬å››è½®å‚æ•°ä¼˜åŒ– (æ–¹æ¡ˆ1:ç»Ÿä¸€æµ‹è¯•)")
    log_message("="*80)
    log_message(f"\nä¼˜åŒ–å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    log_message(f"ç»“æœæ–‡ä»¶: {results_file}")
    log_message(f"æ£€æŸ¥ç‚¹æ–‡ä»¶: {checkpoint_file}")
    
    log_message("\nğŸ“Š æœ€æ–°ç»“æœåˆ†æ (2025-10-14 22:45):")
    log_message("  â€¢ RandomForest: RÂ²=0.9290 (â†“ from 0.9430)")
    log_message("  â€¢ LSTM: RÂ²=0.7227 (â†“â†“ from 0.8768)")
    log_message("  â€¢ Transformer: RÂ²=-1.2344 (ä»è¿‡æ‹Ÿåˆ)")
    
    log_message("\nğŸ¯ ä¼˜åŒ–ç›®æ ‡:")
    log_message("  1. LSTMæ¢å¤åˆ°RÂ²>0.87 (ç¬¬äºŒè½®æœ€ä½³æ°´å¹³)")
    log_message("  2. Transformerè¾¾åˆ°RÂ²>0 (å¯ç”¨æ°´å¹³)")
    log_message("  3. RandomForestç¨³å®šåœ¨RÂ²>0.92")
    
    # =============================================================================
    # ç»Ÿä¸€å®éªŒé…ç½® - æ¯æ¬¡åŒæ—¶ä¼˜åŒ–LSTMå’ŒTransformer
    # =============================================================================
    log_message("\n" + "="*80)
    log_message("ğŸ“ ä¼˜åŒ–ç­–ç•¥ (æ–¹æ¡ˆ1: ç»Ÿä¸€æµ‹è¯•):")
    log_message("="*80)
    log_message("  ç­–ç•¥: æ¯æ¬¡å®éªŒåŒæ—¶è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
    log_message("  ä¼˜åŠ¿: å‡å°‘æ€»å®éªŒæ¬¡æ•°ï¼Œä¾¿äºæ¨ªå‘å¯¹æ¯”")
    log_message("  LSTMç›®æ ‡: æ¢å¤åˆ°RÂ²>0.87")
    log_message("  Transformerç›®æ ‡: è¾¾åˆ°RÂ²>0")
    
    # ç»Ÿä¸€çš„å®éªŒé…ç½®åˆ—è¡¨
    unified_configs = [
        # é…ç½®1: LSTMåŸºçº¿ + Transformeræç®€
        {
            'name': 'Exp_01_Baseline',
            'lstm_config': {
                'units': [64, 32],
                'dropout': 0.2,
                'epochs': 150,
                'batch_size': 8
            },
            'transformer_config': {
                'd_model': 16,
                'num_heads': 2,
                'num_layers': 1,
                'dff': 64,
                'dropout': 0.6,
                'epochs': 100,
                'batch_size': 8
            },
            'description': 'LSTMç¬¬äºŒè½®æœ€ä½³é…ç½® + Transformeræç®€é…ç½®'
        },
        
        # é…ç½®2: LSTMä½dropout + Transformerè¶…è½»é‡
        {
            'name': 'Exp_02_LowDropout',
            'lstm_config': {
                'units': [64, 32],
                'dropout': 0.15,
                'epochs': 150,
                'batch_size': 8
            },
            'transformer_config': {
                'd_model': 24,
                'num_heads': 2,
                'num_layers': 1,
                'dff': 96,
                'dropout': 0.5,
                'epochs': 120,
                'batch_size': 8
            },
            'description': 'LSTMä½dropout(0.15) + Transformerè¶…è½»é‡'
        },
        
        # é…ç½®3: LSTMæ›´ä½dropout + Transformerå°æ¨¡å‹
        {
            'name': 'Exp_03_MinDropout',
            'lstm_config': {
                'units': [64, 32],
                'dropout': 0.1,
                'epochs': 150,
                'batch_size': 8
            },
            'transformer_config': {
                'd_model': 32,
                'num_heads': 2,
                'num_layers': 1,
                'dff': 128,
                'dropout': 0.5,
                'epochs': 150,
                'batch_size': 8
            },
            'description': 'LSTMæä½dropout(0.10) + Transformerå°æ¨¡å‹é•¿è®­ç»ƒ'
        },
        
        # é…ç½®4: LSTMå®½ç½‘ç»œ + Transformerå¤šå¤´æ³¨æ„åŠ›
        {
            'name': 'Exp_04_WideNetwork',
            'lstm_config': {
                'units': [96, 48],
                'dropout': 0.2,
                'epochs': 120,
                'batch_size': 8
            },
            'transformer_config': {
                'd_model': 32,
                'num_heads': 4,
                'num_layers': 1,
                'dff': 128,
                'dropout': 0.5,
                'epochs': 100,
                'batch_size': 8
            },
            'description': 'LSTMå®½ç½‘ç»œ(96-48) + Transformerå¤šå¤´æ³¨æ„åŠ›(4å¤´)'
        },
        
        # é…ç½®5: LSTMæ·±ç½‘ç»œ + Transformerä¸¤å±‚
        {
            'name': 'Exp_05_DeepNetwork',
            'lstm_config': {
                'units': [96, 64, 32],
                'dropout': 0.2,
                'epochs': 120,
                'batch_size': 8
            },
            'transformer_config': {
                'd_model': 16,
                'num_heads': 2,
                'num_layers': 2,
                'dff': 64,
                'dropout': 0.6,
                'epochs': 100,
                'batch_size': 8
            },
            'description': 'LSTMæ·±ç½‘ç»œ(3å±‚) + Transformerä¸¤å±‚æç®€'
        },
        
        # é…ç½®6: LSTMå®½ç½‘ç»œä½dropout + Transformerå¹³è¡¡é…ç½®
        {
            'name': 'Exp_06_Balanced',
            'lstm_config': {
                'units': [96, 48],
                'dropout': 0.15,
                'epochs': 150,
                'batch_size': 8
            },
            'transformer_config': {
                'd_model': 24,
                'num_heads': 4,
                'num_layers': 1,
                'dff': 96,
                'dropout': 0.4,
                'epochs': 120,
                'batch_size': 8
            },
            'description': 'LSTMå®½ç½‘ç»œä½dropout + Transformerå¹³è¡¡é…ç½®'
        },
        
        # é…ç½®7: å°batchè®­ç»ƒ
        {
            'name': 'Exp_07_SmallBatch',
            'lstm_config': {
                'units': [64, 32],
                'dropout': 0.2,
                'epochs': 150,
                'batch_size': 4
            },
            'transformer_config': {
                'd_model': 32,
                'num_heads': 2,
                'num_layers': 1,
                'dff': 128,
                'dropout': 0.5,
                'epochs': 120,
                'batch_size': 4
            },
            'description': 'ä¸¤ä¸ªæ¨¡å‹éƒ½ä½¿ç”¨å°batch(4)'
        },
        
        # é…ç½®8: LSTMå¤§ç½‘ç»œé«˜æ­£åˆ™ + Transformerä¸­ç­‰é…ç½®
        {
            'name': 'Exp_08_LargeNetwork',
            'lstm_config': {
                'units': [128, 64],
                'dropout': 0.25,
                'epochs': 120,
                'batch_size': 8
            },
            'transformer_config': {
                'd_model': 48,
                'num_heads': 4,
                'num_layers': 1,
                'dff': 192,
                'dropout': 0.4,
                'epochs': 100,
                'batch_size': 8
            },
            'description': 'LSTMå¤§ç½‘ç»œé«˜æ­£åˆ™ + Transformerä¸­ç­‰é…ç½®'
        },
        
        # é…ç½®9: å¹³è¡¡é…ç½®A
        {
            'name': 'Exp_09_Balanced_A',
            'lstm_config': {
                'units': [80, 40],
                'dropout': 0.18,
                'epochs': 140,
                'batch_size': 8
            },
            'transformer_config': {
                'd_model': 28,
                'num_heads': 4,
                'num_layers': 1,
                'dff': 112,
                'dropout': 0.45,
                'epochs': 120,
                'batch_size': 8
            },
            'description': 'ä¸¤æ¨¡å‹å¹³è¡¡é…ç½®A'
        },
        
        # é…ç½®10: å¹³è¡¡é…ç½®B
        {
            'name': 'Exp_10_Balanced_B',
            'lstm_config': {
                'units': [72, 36],
                'dropout': 0.16,
                'epochs': 140,
                'batch_size': 8
            },
            'transformer_config': {
                'd_model': 20,
                'num_heads': 4,
                'num_layers': 1,
                'dff': 80,
                'dropout': 0.5,
                'epochs': 130,
                'batch_size': 8
            },
            'description': 'ä¸¤æ¨¡å‹å¹³è¡¡é…ç½®B'
        },
    ]
    

    
    # =============================================================================
    # æ‰§è¡Œä¼˜åŒ–å®éªŒ
    # =============================================================================
    
    total_experiments = len(unified_configs)
    
    log_message("\n" + "="*80)
    log_message("ğŸš€ å¼€å§‹ç»Ÿä¸€ä¼˜åŒ–å®éªŒ")
    log_message(f"æ€»è®¡ {total_experiments} ä¸ªé…ç½®ï¼Œæ¯æ¬¡åŒæ—¶è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
    log_message("="*80)
    
    for i, config_info in enumerate(unified_configs, 1):
        # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
        if i - 1 < start_idx:
            log_message(f"â­ï¸  è·³è¿‡å·²å®Œæˆçš„å®éªŒ {i}/{total_experiments}")
            continue
        log_message(f"\n{'='*80}")
        log_message(f"ğŸ“Š æ€»è¿›åº¦: {i}/{total_experiments}")
        log_message(f"ğŸ§ª å®éªŒ: {config_info['name']}")
        log_message(f"ğŸ“ è¯´æ˜: {config_info['description']}")
        log_message(f"{'='*80}")
        
        # åˆ›å»ºå®Œæ•´é…ç½®
        full_config = DEFAULT_CONFIG.copy()
        full_config['lstm_config'] = config_info['lstm_config']
        full_config['transformer_config'] = config_info['transformer_config']
        
        # è¿è¡Œå®éªŒï¼ˆè®­ç»ƒæ‰€æœ‰æ¨¡å‹ï¼‰
        results = run_experiment(full_config, config_info['name'])
        
        if results:
            if 'error' in results:
                # è®°å½•å¤±è´¥çš„å®éªŒï¼ˆè®°å½•æ‰€æœ‰æ¨¡å‹ï¼‰
                for model_name in ['lstm', 'transformer', 'random_forest']:
                    all_results.append({
                        'experiment': config_info['name'],
                        'model': model_name,
                        'description': config_info['description'],
                        'lstm_config': config_info['lstm_config'],
                        'transformer_config': config_info['transformer_config'],
                        'RÂ²': np.nan,
                        'RMSE': np.nan,
                        'MAE': np.nan,
                        'MAPE': np.nan,
                        'error': results['error']
                    })
            else:
                # è®°å½•æ‰€æœ‰æ¨¡å‹çš„ç»“æœ
                for model_name in ['lstm', 'transformer', 'random_forest']:
                    if model_name in results:
                        all_results.append({
                            'experiment': config_info['name'],
                            'model': model_name,
                            'description': config_info['description'],
                            'lstm_config': config_info['lstm_config'],
                            'transformer_config': config_info['transformer_config'],
                            **results[model_name]
                        })
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ä¼˜ç§€æ°´å¹³
                if 'lstm' in results:
                    lstm_r2 = results['lstm'].get('RÂ²', 0)
                    if lstm_r2 >= 0.87:
                        log_message(f"\nğŸ‰ LSTMè¾¾åˆ°ç›®æ ‡! RÂ²={lstm_r2:.4f} >= 0.87")
                
                if 'transformer' in results:
                    trans_r2 = results['transformer'].get('RÂ²', -999)
                    if trans_r2 > 0:
                        log_message(f"\nğŸ‰ Transformeré¦–æ¬¡è¾¾åˆ°æ­£RÂ²! RÂ²={trans_r2:.4f}")
                    if trans_r2 >= 0.5:
                        log_message(f"\nğŸ† Transformerè¾¾åˆ°ä¼˜ç§€æ°´å¹³! RÂ²={trans_r2:.4f} >= 0.5")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹å’Œä¸­é—´ç»“æœ
            checkpoint_data = {
                'last_completed_idx': i - 1,
                'results': all_results,
                'timestamp': datetime.now().isoformat()
            }
            save_checkpoint(checkpoint_data, checkpoint_file)
            save_intermediate_results(all_results, results_file)
    
    # =============================================================================
    # ç”Ÿæˆç»“æœæŠ¥å‘Š
    # =============================================================================
    
    log_message("\n" + "="*80)
    log_message("ğŸ“Š ç”Ÿæˆä¼˜åŒ–ç»“æœæŠ¥å‘Š")
    log_message("="*80)
    
    # è½¬æ¢ä¸ºDataFrame
    df_results = pd.DataFrame(all_results)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    with open(results_file, 'w', encoding='utf-8') as f:
        f.write("="*100 + "\n")
        f.write("ç¢³ä»·æ ¼é¢„æµ‹ç³»ç»Ÿ - ç¬¬å››è½®å‚æ•°ä¼˜åŒ–ç»“æœ (æ–¹æ ˆ1:ç»Ÿä¸€æµ‹è¯•)\n")
        f.write("="*100 + "\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ€»å®éªŒæ¬¡æ•°: {len(unified_configs)} (æ¯æ¬¡è®­ç»ƒæ‰€æœ‰æ¨¡å‹)\n\n")
        
        # æŒ‰æ¨¡å‹åˆ†ç»„æ˜¾ç¤ºç»“æœ
        for model_type in ['lstm', 'transformer', 'random_forest']:
            model_results = df_results[df_results['model'] == model_type].copy()
            if not model_results.empty:
                model_results = model_results.sort_values('RÂ²', ascending=False)
                
                f.write(f"\n{'='*100}\n")
                f.write(f"ğŸ“Š {model_type.upper()} æ¨¡å‹ä¼˜åŒ–ç»“æœ\n")
                f.write("="*100 + "\n\n")
                
                f.write(f"{'æ’å':<6} {'å®éªŒåç§°':<35} {'RÂ²':<10} {'RMSE':<10} {'MAE':<10} {'MAPE':<10}\n")
                f.write("-"*100 + "\n")
                
                for idx, row in enumerate(model_results.itertuples(), 1):
                    medal = "ğŸ¥‡" if idx == 1 else "ğŸ¥ˆ" if idx == 2 else "ğŸ¥‰" if idx == 3 else f"{idx:2d}"
                    r2_val = getattr(row, 'RÂ²', np.nan)
                    rmse_val = getattr(row, 'RMSE', np.nan)
                    mae_val = getattr(row, 'MAE', np.nan)
                    mape_val = getattr(row, 'MAPE', np.nan)
                    exp_name = getattr(row, 'experiment', '')
                    f.write(f"{medal:<6} {exp_name:<35} {r2_val:<10.4f} {rmse_val:<10.2f} {mae_val:<10.2f} {mape_val:<10.2f}%\n")
                
                # æœ€ä½³é…ç½®
                best = model_results.iloc[0]
                f.write("\n" + "="*100 + "\n")
                f.write(f"ğŸ† {model_type.upper()}æœ€ä½³é…ç½®\n")
                f.write("="*100 + "\n")
                f.write(f"å®éªŒ: {best['experiment']}\n")
                f.write(f"è¯´æ˜: {best['description']}\n")
                f.write(f"RÂ²: {best['RÂ²']:.4f}\n")
                f.write(f"RMSE: {best['RMSE']:.2f}\n")
                f.write(f"MAE: {best['MAE']:.2f}\n")
                f.write(f"MAPE: {best['MAPE']:.2f}%\n\n")
                
                # LSTMå’ŒTransformeræ˜¾ç¤ºå¯¹åº”çš„é…ç½®å‚æ•°
                if model_type == 'lstm' and 'lstm_config' in best:
                    f.write("LSTMé…ç½®å‚æ•°:\n")
                    for key, value in best['lstm_config'].items():
                        f.write(f"  {key}: {value}\n")
                elif model_type == 'transformer' and 'transformer_config' in best:
                    f.write("Transformeré…ç½®å‚æ•°:\n")
                    for key, value in best['transformer_config'].items():
                        f.write(f"  {key}: {value}\n")
        
        # å¯¹æ¯”åˆ†æ
        f.write("\n" + "="*100 + "\n")
        f.write("ğŸ“ˆ ä¼˜åŒ–æ•ˆæœå¯¹æ¯”\n")
        f.write("="*100 + "\n\n")
        
        lstm_results = df_results[df_results['model'] == 'lstm'].copy()
        if not lstm_results.empty:
            best_lstm_r2 = lstm_results['RÂ²'].max()
            baseline_lstm_r2 = 0.7227  # æœ€æ–°è¿è¡Œç»“æœ
            target_lstm_r2 = 0.8768    # ç¬¬äºŒè½®æœ€ä½³
            
            f.write(f"LSTMæ¨¡å‹:\n")
            f.write(f"  å½“å‰åŸºçº¿: RÂ² = {baseline_lstm_r2:.4f}\n")
            f.write(f"  ç¬¬äºŒè½®æœ€ä½³: RÂ² = {target_lstm_r2:.4f}\n")
            f.write(f"  æœ¬è½®æœ€ä½³: RÂ² = {best_lstm_r2:.4f}\n")
            f.write(f"  æ”¹è¿›å¹…åº¦: {(best_lstm_r2 - baseline_lstm_r2):.4f}\n")
            
            if best_lstm_r2 >= target_lstm_r2:
                f.write(f"  âœ… è¾¾åˆ°æˆ–è¶…è¶Šç¬¬äºŒè½®æœ€ä½³æ°´å¹³!\n\n")
            else:
                f.write(f"  âš ï¸ æœªè¾¾åˆ°ç¬¬äºŒè½®æ°´å¹³ï¼Œå·®è·: {(target_lstm_r2 - best_lstm_r2):.4f}\n\n")
        
        trans_results = df_results[df_results['model'] == 'transformer'].copy()
        if not trans_results.empty:
            best_trans_r2 = trans_results['RÂ²'].max()
            baseline_trans_r2 = -1.2344
            
            f.write(f"Transformeræ¨¡å‹:\n")
            f.write(f"  å½“å‰åŸºçº¿: RÂ² = {baseline_trans_r2:.4f}\n")
            f.write(f"  æœ¬è½®æœ€ä½³: RÂ² = {best_trans_r2:.4f}\n")
            f.write(f"  æ”¹è¿›å¹…åº¦: {(best_trans_r2 - baseline_trans_r2):.4f}\n")
            
            if best_trans_r2 > 0:
                f.write(f"  âœ… æˆåŠŸè¾¾åˆ°æ­£RÂ²å€¼!\n\n")
            else:
                f.write(f"  âš ï¸ ä»æœªè¾¾åˆ°æ­£RÂ²å€¼\n\n")
        
        # æ¨¡å‹å¯¹æ¯”
        f.write(f"\næ¨¡å‹æ€§èƒ½å¯¹æ¯” (æœ€ä½³é…ç½®):\n")
        f.write("-"*100 + "\n")
        for model_name in ['lstm', 'transformer', 'random_forest']:
            model_data = df_results[df_results['model'] == model_name]
            if not model_data.empty:
                best_r2 = model_data['RÂ²'].max()
                f.write(f"{model_name.upper():<20} RÂ² = {best_r2:.4f}\n")
    
    log_message(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    # æ˜¾ç¤ºæœ€ä½³ç»“æœ
    lstm_results = df_results[df_results['model'] == 'lstm'].copy()
    if not lstm_results.empty:
        lstm_results = lstm_results.sort_values('RÂ²', ascending=False)
        best_lstm = lstm_results.iloc[0]
        log_message(f"\nğŸ† LSTMæœ€ä½³: {best_lstm['experiment']} - RÂ²={best_lstm['RÂ²']:.4f}")
    
    trans_results = df_results[df_results['model'] == 'transformer'].copy()
    if not trans_results.empty:
        trans_results = trans_results.sort_values('RÂ²', ascending=False)
        best_trans = trans_results.iloc[0]
        log_message(f"ğŸ† Transformeræœ€ä½³: {best_trans['experiment']} - RÂ²={best_trans['RÂ²']:.4f}")
    
    rf_results = df_results[df_results['model'] == 'random_forest'].copy()
    if not rf_results.empty:
        rf_results = rf_results.sort_values('RÂ²', ascending=False)
        best_rf = rf_results.iloc[0]
        log_message(f"ğŸ† RandomForestæœ€ä½³: {best_rf['experiment']} - RÂ²={best_rf['RÂ²']:.4f}")
    
    log_message(f"\nä¼˜åŒ–å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ¸…ç†æ£€æŸ¥ç‚¹æ–‡ä»¶
    try:
        if os.path.exists(checkpoint_file):
            os.remove(checkpoint_file)
            log_message(f"ğŸ—‘ï¸  å·²æ¸…ç†æ£€æŸ¥ç‚¹æ–‡ä»¶: {checkpoint_file}")
    except:
        pass
    
    log_message("="*80)
    log_message("\n" + "="*80)
    log_message("ğŸ‰ ç¬¬å››è½®å‚æ•°ä¼˜åŒ–åœ†æ»¡å®Œæˆ!")
    log_message("="*80)
    
    return results_file

def quick_test(config_name='exp_baseline'):
    """å¿«é€Ÿæµ‹è¯•å•ä¸ªé…ç½®
    
    Args:
        config_name: é…ç½®åç§°
    """
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_file = f'parameter/quick_test_{config_name}_{timestamp}.txt'
    
    # é¢„å®šä¹‰çš„å¿«é€Ÿæµ‹è¯•é…ç½®
    quick_configs = {
        'exp_baseline': {
            'name': 'Quick_Baseline',
            'lstm_config': {
                'units': [64, 32],
                'dropout': 0.2,
                'epochs': 150,
                'batch_size': 8
            },
            'transformer_config': {
                'd_model': 16,
                'num_heads': 2,
                'num_layers': 1,
                'dff': 64,
                'dropout': 0.6,
                'epochs': 100,
                'batch_size': 8
            }
        }
    }
    
    if config_name not in quick_configs:
        print(f"âŒ æœªçŸ¥é…ç½®: {config_name}")
        print(f"å¯ç”¨é…ç½®: {', '.join(quick_configs.keys())}")
        return
    
    config_info = quick_configs[config_name]
    
    # åˆ›å»ºå®Œæ•´é…ç½®
    full_config = DEFAULT_CONFIG.copy()
    full_config['lstm_config'] = config_info['lstm_config']
    full_config['transformer_config'] = config_info['transformer_config']
    
    print(f"ğŸš€ å¿«é€Ÿæµ‹è¯•: {config_info['name']}")
    print(f"LSTMé…ç½®: {config_info['lstm_config']}")
    print(f"Transformeré…ç½®: {config_info['transformer_config']}")
    print()
    
    # è¿è¡Œå®éªŒ
    results = run_experiment(full_config, config_info['name'])
    
    if results and 'error' not in results:
        print(f"\nâœ… æµ‹è¯•å®Œæˆ!")
        for model_name, metrics in results.items():
            print(f"\n{model_name.upper()} ç»“æœ:")
            print(f"  RÂ² = {metrics.get('RÂ²', 0):.4f}")
            print(f"  RMSE = {metrics.get('RMSE', 0):.2f}")
            print(f"  MAE = {metrics.get('MAE', 0):.2f}")
            print(f"  MAPE = {metrics.get('MAPE', 0):.2f}%")
    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥")
    
    print(f"\nç»“æœæ–‡ä»¶: {results_file}")

if __name__ == '__main__':
    main()
