# 第二轮参数优化方案

**制定时间**: 2025-10-24 23:42  
**基于版本**: 优化版本1 (20251024_234051)  
**目标**: 提升R²至正值，增强方向准确率，平衡特征重要性

---

## 🎯 优化目标

### 核心指标目标
| 指标 | 当前值 | 目标值 | 优先级 |
|------|--------|--------|--------|
| **R²** | -0.28 | **> 0.3** | 🔴 最高 |
| **MAPE** | 4.81% | **< 5%** | 🟢 保持 |
| **方向准确率** | 53.74% | **> 60%** | 🟡 重要 |
| **特征平衡** | price_lag_1占78.5% | **< 40%** | 🟡 重要 |

---

## 📊 问题诊断与根因分析

### 问题1: R²为负 (-0.28)
**根本原因**:
1. ❌ **损失函数与评估指标不匹配**
   - 当前: 80% Huber + 20% 方向损失
   - 问题: 方向损失不优化MSE，导致R²下降
   
2. ❌ **测试集表现差于训练集**
   - 可能的数据泄露已修复，但泛化能力不足
   - 验证损失0.43，但测试MSE=6.52（反归一化后）

3. ❌ **模型容量vs数据量不匹配**
   - 参数量: 58.9万
   - 训练样本: 795
   - 过参数化风险高

### 问题2: 过度依赖price_lag_1 (78.5%)
**根本原因**:
1. ❌ **特征间信息不平衡**
   - price_lag_1包含最直接的价格信息
   - 技术指标信息冗余，被模型忽略

2. ❌ **Attention机制未能有效工作**
   - 当前仅一个Attention层
   - 未能分散注意力到多样化特征

3. ❌ **缺乏显式的特征正则化**
   - 无机制防止过度依赖单一特征

### 问题3: 方向准确率低 (53.74%)
**根本原因**:
1. ❌ **方向损失权重过低** (仅20%)
2. ❌ **缺乏专门的方向分类头**
3. ❌ **碳价格序列的固有随机性**

---

## 🔧 优化策略 (三个方向)

### 策略A: 保守优化 - 微调当前架构
**适用场景**: 希望保持MAPE优势，逐步提升R²

#### A1. 调整损失函数权重
```python
# 从 80% Huber + 20% 方向
# 改为 95% Huber + 5% 方向
total_loss = 0.95 * huber + 0.05 * direction_component
```
**预期**: R²提升，MAPE略微上升

#### A2. 降低模型复杂度
```python
CONFIG = {
    'lstm_units': 128,        # 256 → 128
    'lstm_units_2': 64,       # 128 → 64
    'lstm_units_3': 32,       # 64 → 32 (移除或减小)
    'attention_dim': 64,      # 128 → 64
    'dropout_rate': 0.3,      # 0.4 → 0.3
}
```
**预期**: 减少过拟合，提升泛化能力

#### A3. 增加训练数据增强
- 添加高斯噪声 (sigma=0.01)
- Temporal cutout (随机遮盖部分时间步)

**优点**: 风险低，改动小  
**缺点**: 提升有限

---

### 策略B: 激进优化 - 双头架构 ⭐推荐
**适用场景**: 同时优化R²和方向准确率

#### B1. 设计双输出头架构
```python
# 主路径 (LSTM + Attention)
lstm_out → attention → dense_shared

# 分支1: 回归头 (优化R²和MAPE)
dense_shared → dense_regression(64) → output_value

# 分支2: 分类头 (优化方向准确率)
dense_shared → dense_direction(32) → output_direction (3分类: 涨/跌/平)
```

#### B2. 多任务损失函数
```python
def multi_task_loss(y_true, y_pred_value, y_pred_direction):
    # 回归损失 (70%)
    regression_loss = huber_loss(y_true, y_pred_value)
    
    # 方向分类损失 (30%)
    direction_labels = compute_direction_labels(y_true)
    direction_loss = categorical_crossentropy(direction_labels, y_pred_direction)
    
    return 0.7 * regression_loss + 0.3 * direction_loss
```

#### B3. 特征重要性正则化
```python
# 在训练过程中添加特征选择层
feature_weights = Dense(n_features, activation='softmax')(inputs)
weighted_features = inputs * feature_weights

# 添加熵正则化，鼓励权重分散
entropy_loss = -tf.reduce_sum(feature_weights * tf.log(feature_weights + 1e-10))
total_loss += 0.01 * entropy_loss  # 惩罚过于集中的权重
```

**配置调整**:
```python
CONFIG = {
    'sequence_length': 60,      # 90 → 60 (降低复杂度)
    'batch_size': 32,           # 16 → 32 (稳定训练)
    'learning_rate': 0.0005,    # 0.0001 → 0.0005 (加快收敛)
    'lstm_units': 128,          # 256 → 128
    'lstm_units_2': 64,         # 128 → 64
    'dropout_rate': 0.35,       # 0.4 → 0.35
    'l2_reg': 0.0005,          # 0.001 → 0.0005
}
```

**优点**: 针对性强，有望显著提升  
**缺点**: 代码改动较大

---

### 策略C: 特征工程优化
**适用场景**: 根本解决特征不平衡问题

#### C1. 引入差分特征
```python
# 减少对绝对价格的依赖，增加相对变化
df['price_diff_1'] = df[target].diff(1)
df['price_diff_5'] = df[target].diff(5)
df['price_pct_change_1'] = df[target].pct_change(1)
df['price_pct_change_5'] = df[target].pct_change(5)
```

#### C2. 高阶技术指标
```python
# 布林带
df['bb_upper'] = df['ma_20'] + 2 * df['volatility_20']
df['bb_lower'] = df['ma_20'] - 2 * df['volatility_20']
df['bb_position'] = (df[target] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])

# MACD
df['macd'] = df['ema_12'] - df['ema_26']
df['macd_signal'] = df['macd'].ewm(span=9).mean()
df['macd_hist'] = df['macd'] - df['macd_signal']
```

#### C3. 外部特征增强
```python
# 时间特征
df['day_of_week'] = df.index.dayofweek
df['month'] = df.index.month
df['quarter'] = df.index.quarter

# 价格区间特征
df['price_percentile'] = df[target].rolling(window=60).apply(
    lambda x: percentileofscore(x, x.iloc[-1])
)
```

#### C4. 特征选择
- 使用Lasso或随机森林预筛选特征
- 移除相关性>0.95的冗余特征
- 保留25-35个最重要的特征

**优点**: 治本，提升模型质量  
**缺点**: 需要反复实验

---

## 🎯 推荐方案: 策略B + 部分C

### 第一阶段 (立即执行)
1. **实施双头架构** (策略B)
   - 回归头: 优化MAPE和R²
   - 分类头: 提升方向准确率
   - 多任务学习平衡两个目标

2. **降低模型复杂度**
   - LSTM: 256→128, 128→64
   - 序列长度: 90→60
   - 减少过拟合风险

3. **调整训练参数**
   - batch_size: 16→32
   - learning_rate: 0.0001→0.0005
   - 损失权重: 70% 回归 + 30% 分类

### 第二阶段 (视第一阶段结果)
4. **特征工程优化** (策略C)
   - 添加差分特征减少对绝对价格依赖
   - 引入布林带、MACD等高阶指标
   - 特征选择筛除冗余

5. **超参数微调** (策略A)
   - 根据第一阶段结果精细调整
   - Grid Search优化关键参数

---

## 📊 预期效果

### 保守估计 (策略B)
| 指标 | 当前值 | 预期值 | 提升幅度 |
|------|--------|--------|----------|
| R² | -0.28 | **0.2~0.4** | +0.48~0.68 |
| MAPE | 4.81% | **5~7%** | -1~2% (可接受) |
| 方向准确率 | 53.74% | **58~62%** | +4~8% |
| price_lag_1占比 | 78.5% | **50~60%** | -18~28% |

### 乐观估计 (策略B + C)
| 指标 | 当前值 | 预期值 | 提升幅度 |
|------|--------|--------|----------|
| R² | -0.28 | **0.4~0.6** | +0.68~0.88 |
| MAPE | 4.81% | **4~6%** | ±1% |
| 方向准确率 | 53.74% | **62~68%** | +8~14% |
| price_lag_1占比 | 78.5% | **40~50%** | -28~38% |

---

## 🚀 实施计划

### Phase 1: 双头架构实现 (2-3小时)
- [ ] 修改模型架构，添加分类头
- [ ] 实现多任务损失函数
- [ ] 调整配置参数
- [ ] 训练并评估第一版

### Phase 2: 结果分析与微调 (1-2小时)
- [ ] 分析Phase 1结果
- [ ] 识别瓶颈
- [ ] 微调超参数
- [ ] 重新训练

### Phase 3: 特征工程优化 (可选, 3-4小时)
- [ ] 添加差分和高阶特征
- [ ] 特征选择实验
- [ ] 最终训练与评估

---

## 📝 风险与备选方案

### 风险1: 双头架构过拟合
**应对**: 增加Dropout至0.45，减小分类头尺寸

### 风险2: 方向分类损失过高
**应对**: 将权重从30%降至20%，逐步调整

### 风险3: R²仍为负
**应对**: 
- 切换回纯回归损失 (100% MSE)
- 尝试其他架构 (Transformer, TCN)
- 重新审视数据质量

---

## 🔬 实验记录模板

```markdown
### 实验X: [实验名称]
- **日期**: YYYY-MM-DD HH:MM
- **配置变更**: [列出关键参数改动]
- **训练时间**: XX分钟
- **结果**:
  - R²: X.XX
  - MAPE: X.XX%
  - 方向准确率: XX.XX%
- **观察**: [关键发现]
- **下一步**: [改进方向]
```

---

## ✅ 成功标准

**最低标准** (必须达成):
- ✅ R² > 0
- ✅ MAPE < 8%
- ✅ 方向准确率 > 55%

**理想标准** (努力方向):
- 🎯 R² > 0.4
- 🎯 MAPE < 5%
- 🎯 方向准确率 > 60%
- 🎯 price_lag_1占比 < 50%

**卓越标准** (最终目标):
- 🏆 R² > 0.6
- 🏆 MAPE < 4%
- 🏆 方向准确率 > 65%
- 🏆 特征重要性分布均衡

---

**制定人**: AI Assistant  
**审核**: 待用户确认  
**执行**: 待批准后立即开始
