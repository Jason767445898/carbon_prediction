#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‚æ•°è°ƒä¼˜è„šæœ¬
ç”¨äºè°ƒæ•´LSTMå’ŒTransformeræ¨¡å‹çš„è¶…å‚æ•°
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/Users/Jason/Desktop/code/AI')

from carbon_price_prediction import CarbonPricePredictionSystem

def create_tuning_log():
    """åˆ›å»ºå‚æ•°è°ƒä¼˜æ—¥å¿—æ–‡ä»¶"""
    log_content = [
        "==========================================",
        "ç¢³ä»·æ ¼é¢„æµ‹æ¨¡å‹å‚æ•°è°ƒä¼˜è®°å½•",
        "==========================================",
        f"è°ƒä¼˜å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "è°ƒä¼˜ç›®æ ‡:",
        "- æå‡LSTMå’ŒTransformeræ¨¡å‹çš„é¢„æµ‹æ€§èƒ½",
        "- ä¼˜åŒ–è¶…å‚æ•°é…ç½®",
        "- è®°å½•è°ƒä¼˜è¿‡ç¨‹å’Œç»“æœ",
        "",
        "==========================================",
        ""
    ]
    
    with open('parameter_tuning.txt', 'w', encoding='utf-8') as f:
        f.write('\n'.join(log_content))
    
    print("å·²åˆ›å»ºå‚æ•°è°ƒä¼˜æ—¥å¿—æ–‡ä»¶: parameter_tuning.txt")

def log_tuning_result(config, results, notes=""):
    """è®°å½•è°ƒä¼˜ç»“æœ"""
    log_entry = [
        f"è°ƒä¼˜æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "é…ç½®å‚æ•°:",
        f"  LSTMé…ç½®: {config.get('lstm_config', 'N/A')}",
        f"  Transformeré…ç½®: {config.get('transformer_config', 'N/A')}",
        "æ¨¡å‹æ€§èƒ½:",
    ]
    
    for model_name, metrics in results.items():
        log_entry.append(f"  {model_name}:")
        for metric, value in metrics.items():
            if metric not in ['predictions', 'actual']:
                log_entry.append(f"    {metric}: {value:.4f}")
    
    if notes:
        log_entry.append(f"å¤‡æ³¨: {notes}")
    
    log_entry.append("-" * 50)
    log_entry.append("")
    
    with open('parameter_tuning.txt', 'a', encoding='utf-8') as f:
        f.write('\n'.join(log_entry))
    
    print("å·²è®°å½•è°ƒä¼˜ç»“æœåˆ° parameter_tuning.txt")

def tune_lstm_parameters():
    """è°ƒä¼˜LSTMæ¨¡å‹å‚æ•°"""
    print("å¼€å§‹è°ƒä¼˜LSTMæ¨¡å‹å‚æ•°...")
    
    # åŸºç¡€é…ç½®
    base_config = {
        'target_column': 'coal_price',
        'sequence_length': 60,
        'test_size': 0.2,
        'validation_size': 0.1,
        'transformer_config': {
            'd_model': 128,
            'num_heads': 8,
            'num_layers': 4,
            'dff': 512,
            'dropout': 0.1,
            'epochs': 50
        }
    }
    
    # LSTMå‚æ•°ç»„åˆ
    lstm_configs = [
        # åŸºç¡€é…ç½®
        {
            'units': [64, 32],
            'dropout': 0.2,
            'epochs': 100,
            'batch_size': 32
        },
        # å¢åŠ ç½‘ç»œå¤æ‚åº¦
        {
            'units': [128, 64, 32],
            'dropout': 0.2,
            'epochs': 100,
            'batch_size': 32
        },
        # è°ƒæ•´dropout
        {
            'units': [64, 32],
            'dropout': 0.3,
            'epochs': 100,
            'batch_size': 32
        },
        # è°ƒæ•´æ‰¹æ¬¡å¤§å°
        {
            'units': [64, 32],
            'dropout': 0.2,
            'epochs': 100,
            'batch_size': 16
        },
        # å¢åŠ è®­ç»ƒè½®æ•°
        {
            'units': [64, 32],
            'dropout': 0.2,
            'epochs': 150,
            'batch_size': 32
        }
    ]
    
    best_lstm_r2 = -float('inf')
    best_lstm_config = None
    best_lstm_results = None
    
    for i, lstm_config in enumerate(lstm_configs):
        print(f"\næµ‹è¯•LSTMé…ç½® {i+1}/{len(lstm_configs)}")
        
        # åˆ›å»ºç³»ç»Ÿå®ä¾‹
        config = base_config.copy()
        config['lstm_config'] = lstm_config
        
        try:
            system = CarbonPricePredictionSystem(config=config)
            system.load_data('data.dta')
            system.preprocess_data()
            system.train_models()
            results, _ = system.evaluate_models()
            
            # è®°å½•ç»“æœ
            log_tuning_result(config, results, f"LSTMé…ç½®æµ‹è¯• {i+1}")
            
            # æ£€æŸ¥LSTMæ¨¡å‹æ€§èƒ½
            if 'lstm' in results:
                lstm_r2 = results['lstm']['RÂ²']
                if lstm_r2 > best_lstm_r2:
                    best_lstm_r2 = lstm_r2
                    best_lstm_config = lstm_config.copy()
                    best_lstm_results = results['lstm'].copy()
                    
        except Exception as e:
            error_msg = f"LSTMé…ç½®æµ‹è¯• {i+1} å¤±è´¥: {str(e)}"
            print(error_msg)
            log_tuning_result(config, {}, error_msg)
    
    return best_lstm_config, best_lstm_results

def tune_transformer_parameters():
    """è°ƒä¼˜Transformeræ¨¡å‹å‚æ•°"""
    print("å¼€å§‹è°ƒä¼˜Transformeræ¨¡å‹å‚æ•°...")
    
    # åŸºç¡€é…ç½®
    base_config = {
        'target_column': 'coal_price',
        'sequence_length': 60,
        'test_size': 0.2,
        'validation_size': 0.1,
        'lstm_config': {
            'units': [64, 32],
            'dropout': 0.2,
            'epochs': 100,
            'batch_size': 32
        }
    }
    
    # Transformerå‚æ•°ç»„åˆ
    transformer_configs = [
        # åŸºç¡€é…ç½®
        {
            'd_model': 128,
            'num_heads': 8,
            'num_layers': 4,
            'dff': 512,
            'dropout': 0.1,
            'epochs': 50
        },
        # å¢åŠ æ¨¡å‹ç»´åº¦
        {
            'd_model': 256,
            'num_heads': 8,
            'num_layers': 4,
            'dff': 512,
            'dropout': 0.1,
            'epochs': 50
        },
        # å¢åŠ æ³¨æ„åŠ›å¤´æ•°
        {
            'd_model': 128,
            'num_heads': 16,
            'num_layers': 4,
            'dff': 512,
            'dropout': 0.1,
            'epochs': 50
        },
        # å¢åŠ å±‚æ•°
        {
            'd_model': 128,
            'num_heads': 8,
            'num_layers': 6,
            'dff': 512,
            'dropout': 0.1,
            'epochs': 50
        },
        # è°ƒæ•´dropout
        {
            'd_model': 128,
            'num_heads': 8,
            'num_layers': 4,
            'dff': 512,
            'dropout': 0.2,
            'epochs': 50
        },
        # å¢åŠ è®­ç»ƒè½®æ•°
        {
            'd_model': 128,
            'num_heads': 8,
            'num_layers': 4,
            'dff': 512,
            'dropout': 0.1,
            'epochs': 100
        }
    ]
    
    best_transformer_r2 = -float('inf')
    best_transformer_config = None
    best_transformer_results = None
    
    for i, transformer_config in enumerate(transformer_configs):
        print(f"\næµ‹è¯•Transformeré…ç½® {i+1}/{len(transformer_configs)}")
        
        # åˆ›å»ºç³»ç»Ÿå®ä¾‹
        config = base_config.copy()
        config['transformer_config'] = transformer_config
        
        try:
            system = CarbonPricePredictionSystem(config=config)
            system.load_data('data.dta')
            system.preprocess_data()
            system.train_models()
            results, _ = system.evaluate_models()
            
            # è®°å½•ç»“æœ
            log_tuning_result(config, results, f"Transformeré…ç½®æµ‹è¯• {i+1}")
            
            # æ£€æŸ¥Transformeræ¨¡å‹æ€§èƒ½
            if 'transformer' in results:
                transformer_r2 = results['transformer']['RÂ²']
                if transformer_r2 > best_transformer_r2:
                    best_transformer_r2 = transformer_r2
                    best_transformer_config = transformer_config.copy()
                    best_transformer_results = results['transformer'].copy()
                    
        except Exception as e:
            error_msg = f"Transformeré…ç½®æµ‹è¯• {i+1} å¤±è´¥: {str(e)}"
            print(error_msg)
            log_tuning_result(config, {}, error_msg)
    
    return best_transformer_config, best_transformer_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å‚æ•°è°ƒä¼˜...")
    
    # åˆ›å»ºè°ƒä¼˜æ—¥å¿—
    create_tuning_log()
    
    # è°ƒä¼˜LSTMå‚æ•°
    print("\n" + "="*60)
    print("LSTMæ¨¡å‹å‚æ•°è°ƒä¼˜")
    print("="*60)
    best_lstm_config, best_lstm_results = tune_lstm_parameters()
    
    # è°ƒä¼˜Transformerå‚æ•°
    print("\n" + "="*60)
    print("Transformeræ¨¡å‹å‚æ•°è°ƒä¼˜")
    print("="*60)
    best_transformer_config, best_transformer_results = tune_transformer_parameters()
    
    # è®°å½•æœ€ä½³é…ç½®
    print("\n" + "="*60)
    print("å‚æ•°è°ƒä¼˜å®Œæˆ - æœ€ä½³é…ç½®")
    print("="*60)
    
    final_log = [
        "æœ€ç»ˆè°ƒä¼˜ç»“æœ:",
        "=============",
        f"æœ€ä½³LSTMé…ç½®: {best_lstm_config}",
        f"  RÂ²: {best_lstm_results['RÂ²']:.4f}" if best_lstm_results else "  RÂ²: N/A",
        f"  RMSE: {best_lstm_results['RMSE']:.4f}" if best_lstm_results else "  RMSE: N/A",
        "",
        f"æœ€ä½³Transformeré…ç½®: {best_transformer_config}",
        f"  RÂ²: {best_transformer_results['RÂ²']:.4f}" if best_transformer_results else "  RÂ²: N/A",
        f"  RMSE: {best_transformer_results['RMSE']:.4f}" if best_transformer_results else "  RMSE: N/A",
        "",
        f"è°ƒä¼˜ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "=========================================="
    ]
    
    with open('parameter_tuning.txt', 'a', encoding='utf-8') as f:
        f.write('\n'.join(final_log))
    
    print("å‚æ•°è°ƒä¼˜å·²å®Œæˆï¼Œè¯¦ç»†è®°å½•è¯·æŸ¥çœ‹ parameter_tuning.txt")

if __name__ == "__main__":
    main()